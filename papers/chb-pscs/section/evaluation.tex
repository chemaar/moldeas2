In order to evaluate if the approach to generate Linked Data from PSCs can improve the access to public procurement data 
exploiting the advantages of this initiative two experiments have been designed:
\begin{enumerate}
 \item The first one checks if we can access more public procurement notices when the links between a PSC and the CPV are created. 
 The aim of this study is to compare the initial input vocabulary (containing only the CPV descriptors) and the final 
 input vocabulary (containing all descriptors that have been linked to the CPV). Therefore if we extend the input vocabulary we can ease the access to 
 more public procurement notices because we can jump from any PSC to the CPV. In the same way if we need to make some kind of comparison 
 between systems working with different PSCs we can use the CPV as \textit{lingua franca}.
 
 \item The second study tries to exploit the semantic relationships between the CPV concepts to build a recommender of CPV codes for business users. 
 In order to make a empirical experiment we have used $11$ real user queries and their translation into CPV codes made by the company ``Euroalert.net''.
\end{enumerate}

\subsection{Study 1}
\subsection{Research Design}
The purpose of this study is to compare the size of the initial input vocabulary for retrieving public procurement notices 
with regards to the final input vocabulary when links between a PSC and the CPV are created. The exploitation of these links can be used 
to build new SPARQL queries that can take advantage of Linked Data principles to provide a greater input vocabulary. Let's assume the following points about the 
public procurement notices and the PSCs used in this study:
\begin{itemize}
 \item All public procurement notices are always annotated by, at least, one CPV element.
 \item Each PSC is a controlled vocabulary. The CPV is a controlled vocabulary $\mathcal{V}$ comprised of $10357$ elements/terms/codes.
 \item The public procurement notices is a RDF dataset, $\mathcal{D}$,
 Each document $d \in \mathcal{D}$ is annotated, at least, using a CPV code $v \in \mathcal{V}$. Thus, 
 if a query contains all elements $v \in \mathcal{V}$ the entire dataset of notices will be retrieved.
\end{itemize}
Once these assumptions are defined, the gain of linking a new finite PSC to the CPV can be calculated as follows:
\begin{itemize}
 \item The source controlled vocabulary $\mathcal{V}_{psc}$ is comprised of \#$\mathcal{V}_{psc}$ elements.
 \item The linking of terms between a source vocabulary $\mathcal{V}_{psc}$ and  a target vocabulary $\mathcal{V}$ can be carried out in the next ways:
 \begin{enumerate}
  \item $1-1$ link, there are elements $v^k_{psc} \in \mathcal{V}_{psc}$ that are linked to only one element $v \in \mathcal{V}$.
  \item $1-n$ link, there are elements $v^k_{psc} \in \mathcal{V}_{psc}$ that are linked to some elements $v \in \mathcal{V}$ generating $K$ links.  
  \item The result of the previous operation generates links or pairs in the form $p_k=(v^k_{psc}, v^k)$ building a set of pairs $\mathcal{P}=\{p_1,p_2,...,p_k,p_n\}$. Taking into account this situation, 
  the initial vocabulary $V$ is increased in all elements $v^k_{psc} \in \mathcal{V}_{psc}$ that have a link to an element $v \in \mathcal{V}$. The new 
  derivate vocabulary $\mathcal{V'}_{psc}$ is a controlled vocabulary comprising all elements $v^k_{psc}: v^k_{psc} \in p_i$.
 \end{enumerate}
 
 \item The percentage of gain in terms of expressivity (number of elements to be used in queries) is related to the number of elements that enables go from $\mathcal{V}_{psc}$ to $\mathcal{V}$:	
 \begin{equation}\label{percentage}
  \%=100*(\frac{\#\mathcal{V'}_{psc} + \#\mathcal{V}}{\#\mathcal{V}}-1)
 \end{equation}
 
  As an example of this approach, two controlled vocabularies and a set of links/pairs are presented to calculate the gain in terms of expressivity:
  \begin{itemize}
  \item Let $\mathcal{V} = \{A, B, C, D, E\}$  and  $\mathcal{V}_{psc} = \{1, 2, 3\}$ the source and target controlled vocabularies.
  \item Let $P = \{ (A,1), (B,2), (C,1) (C,2) \}$ the set of links/pairs between $\mathcal{V}$ and $\mathcal{V}_{psc}$.
  \item Let $\mathcal{V'}_{psc} = \{ A, B, C \}$ the set of elements $v^k_{psc}: v^k_{psc} \in p_i$.
  \item Therefore, the new controlled vocabulary to query the dataset is comprised of $\{\mathcal{V_{psc}}\,\cup\,\mathcal{V'}_{psc}\}$ and the percentage of gain in terms of expressivity 
  according to the Equation~\ref{percentage} is:

  \begin{equation}
      \% = 100 * \{ \langle (3+3) / 3 \rangle -1 \} = 2-1 = 100 
  \end{equation}
      \item As a consequence the number of final terms to create queries is just two times than the initial set, increasing the expressivity in a $100\%$.
  \end{itemize}

 \item Finally, in this study, there is a specific scenario in which elements $v^k_{psc} \in \mathcal{V}_{psc}$ are not directly mapped to elements $v \in \mathcal{V}$ but 
 assuming that there are relations $r_k$  among elements $v^j_{psc}$  and $v^k_{psc}$ new links could emerge between $v^j_{psc}$ and $v$ through $r_k$. Nevertheless this 
 situation should be avoided in order to prevent an infinite and recursive linking process and keep the advantages of using finite controlled vocabularies, 
 e.g. in the ongoing example the Product Ontology (PO) is used as a bridge classification implying an infinite max gain ($\infty$).
 
\end{itemize}

\subsection{Sample}

The PSCs that have been selected to be promoted to RDF, see Table~\ref{table:pscs-ld}, are also used to check 
the gain we can get through a direct link to the CPV 2008 or by means of creating a ``bridge link'' 
through the ProductOntology. A RDF dataset $\mathcal{D}$ of public procurement notices that contains $919341$ documents 
annotated with a total number of $1866367$ CPV codes ($10062$ are different), has been selected as a sample dataset.


\subsection{Results and Discussion}
Table~\ref{ganancia-terminos} presents the statistics of transforming each PSC as well as the number of terms that have linked to CPV 2008 and the gain (percentage) of 
new descriptors we can use to query the dataset. Following the same approach as in the previous example, the gain in terms 
of expressivity is calculated below:

\begin{itemize}
  \item Let $\mathcal{CPV}_{2003} = \{v^0_{cpv_{2003}}, v^1_{cpv_{2003}},...,v^n_{cpv_{2003}}\}$ and $\mathcal{CPV}_{2008} = \{v^0_{cpv_{2008}}, v^1_{cpv_{2008}},...,v^n_{cpv_{2008}}\}$ the source and target controlled vocabularies.
  \item Let $P = \{ (v^k_{cpv_{2003}},v^j_{cpv_{2008}})\}$ the set of links/pairs between $\mathcal{CPV}_{2003}$ and $\mathcal{CPV}_{2008}$.
  \item Let $\mathcal{CPV'}_{2008} = \{ v^k_{cpv_{2003}} \}$ the set of elements $v^k_{cpv_{2003}}: v^k_{cpv_{2003}} \in p_i$.
  \item Therefore, the new controlled vocabulary to query the dataset is comprised of $\{\mathcal{CPV}_{2008}\,\cup\,\mathcal{CPV'}_{2008}\}$ 
  and the percentage of gain in terms of expressivity according to the Equation~\ref{percentage} is:

  \begin{equation}
      \% = 100 * \{ \langle (462+10357) / 10357 \rangle -1 \} = 1,0446-1 = 4,46 
  \end{equation}
      
 \item As conclusion the real expressivity gain (in terms of descriptors to query a dataset) with regards to the initial set of $10357$ terms in CPV 2008 has been 
 increased in a $4.46$\% (462 new elements can be now used to build SPARQL queries). 

\end{itemize}

Taking into account the full results presented in Table~\ref{ganancia-terminos} the real expressivity gain (in terms of descriptors to query a dataset) 
with regards to the initial set of $10357$ terms in CPV 2008 has been increased in a $209,66$\% 
($21715$ new elements are part of the input vocabulary). Furthermore if the ProductOntology is used as a ``bridge'' the input vocabulary is then 
increased in a $285,66$\% ($29586$ new elements). Although this last approach shows a valuable increment in the number of linked elements 
it should be avoided due to the fact that more ``jumps'' between classifications imply necessarily less confidence in the mappings. Finally 
Figure~\ref{fig:results-3} presents the evolution of the input vocabulary when a new PSC is linked to the CPV 2008.

\begin{table}[!htb]
\scriptsize
\renewcommand{\arraystretch}{1.3}
\begin{center}
\begin{tabular}[c]{|p{2.2cm}|p{1.6cm}|p{1.8cm}|p{1.6cm}|p{1.6cm}|p{1.8cm}|p{1.6cm}|}
 
 \hline
  $\mathcal{V}_{psc}$ & $\#\mathcal{V}_{psc}$  & RDF triples &Links to CPV 2008 &  $\%$ real & Links through PO & $\%$ real trough PO    \\\hline

CPV 2008 	& $10357$  	& $803311$	& $0$	 	& $0$	 	& $10000$	& $96,55$	  \\ \hline
CPV 2003 	& $8323$  	& $546135$	& $462$ 	& $4,46$ 	& $8312$	& $80,25$	 \\ \hline
CN 2012  	& $14552$	& $137484$	& $2390$ 	& $23,08$	& $2390$	& $23,08$	  \\ \hline
CPC 2008 	& $4408$	& $100819$   	& $4402$	& $42,50$	& $4403$	& $42,51$ 	  \\ \hline
CPA 2008 	& $5429$	& $92749$   	& $5399$	& $52,13$	& $5410$	& $52,24$	  \\ \hline
ISIC v4  	& $766$		& $18986$   	& $765$ 	& $7,39$ 	& $765$		& $7,39$	   \\ \hline
NAICS 2007 	& $2328$	& $36292$ 	& $2300$	& $22,21$	& $2300$	& $22,21$	 \\ \hline
NAICS 2012 	& $2212$	& $70887$ 	& $2186$	& $21,11$	& $2186$	& $21,11$	  \\ \hline
SITC v4 	& $4017$	& $3811$   	& $3811$	& $36,80$	& $3820$	& $36,88$	 \\ \hline
\multicolumn{7}{|c|}{\textbf{Total}} \\ \hline
$\star$ 	& $42035$ 	& $1842053$	& $21715$   	& $209,66$	& $29586$ 	& $285,66$	 \\ \hline
\hline
%  \multicolumn{7}{|c|}{\textbf{Linking CPV 2008 and \textit{ProductOntology}}} \\ \hline
%  \textit{PO}& $\infty$	& $10000$   	& N/A	& $96,55$					& $96,55$ 	& $\infty$  \\ \hline
% \multicolumn{8}{|c|}{\textbf{Total including \textit{ProductOntology}}} \\ \hline
% $\star$	 & $\infty$	& $31715$   	& $209,66$	& $306,21$	& $39586$ & $382,21$	& $\infty$ \\ \hline
  \end{tabular}
  \caption{Statistics of promoting to RDF selected PSCs and linking them to the CPV 2008,}\label{ganancia-terminos}  
  
  \end{center}
\end{table}



 \begin{figure}[!ht]
\centering
	\includegraphics[width=\textwidth]{./imgs/fig-5}
 \caption{Evolution of the number of terms when a new PSC is linked to the CPV 2008.}
 \label{fig:results-3}
\end{figure}


\subsection{Study 2}
The aim of this study is to verify if the Linked Data generated from public procurement notices, PSCs, etc. can be exploited to deliver a decision 
support system that helps business users to select CPV codes from user queries in natural language. This study is motivated by the company ``Euroalert.net'' 
that sells an alert service for users (companies, etc.) that want to tender in specific sectors under a certain profile. 
Usually, the most relevant variables in public procurement notices are the CPV codes and the location (NUTS codes). In this experiment 
we simulate the behavior of ``Euroalert.net'' employees when they have to translate user queries, $Q_{str}$, into CPV codes for creating a new alert. 
Basically, the experiment is based on methods for semantic search and concept query expansion, see Figure~\ref{fig:results-6}, that we have designed to 
tackle the recommendation of CPV codes, see Table~\ref{methods-recommending}. 

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.3}
\begin{center}
\begin{tabular}[c]{|l|p{8.5cm}|p{4.5cm}|} 
\hline
\textbf{Method} &  \textbf{Description} &  \textbf{Technology} \\\hline
$M^1$ & CPV English descriptions are indexed and a syntactic search process is performed for each $Q_{str}$ & Apache Lucene y Solr \\ \hline
$M^2$ & CPV codes are selected according to the SKOS taxonomy. Previously, the method $M^1$ is applied to extract CPV codes from natural language & $M^1$ + ranking broader/narrower \\ \hline
$M^3$ & Similar to $M^2$ but codes are selected using \textit{Spreading Activation}& $M^1$ + ONTOSPREAD \\ \hline
$M^4$ & Similar to $M^2$ but codes are selected using the analysis of historical relationships in previous public procurement notices & $M^1$ + Apache Mahout \\ \hline
 \end{tabular}
  \caption{Methods for recommending CPV 2008 codes.}\label{methods-recommending}  
    \end{center}
\end{table}

 \begin{figure}[!ht]
\centering
	\includegraphics[width=6cm]{./imgs/fig-6}
 \caption{Workflow to recommend CPV 2008 codes according to an user query.}
 \label{fig:results-6}
\end{figure}


\subsection{Research Design}
In order to validate the accuracy of the different methods to suggest CPV codes the typical measures of 
precision, see Equation~\ref{eq-1}, recall, see Equation~\ref{eq-2} and F1 score(the harmonic mean of precision and recall), see Equation~\ref{eq-3} will 
be used to compare and select the best method to recommend CPV codes. In particular, $tp$ (true positive) is ``the set of expected CPV codes 
that have been retrieved'', $fp$ is ``the set of un-expected CPV codes that have been retrieved'', 
$tn$ is ``the set of expected CPV codes that have not been retrieved'' and $fn$ is 
``the set of un-expected CPV codes that have not been retrieved''.

\begin{figure}[ht]
\begin{minipage}[b]{0.45\linewidth}
\centering
\begin{equation}\label{eq-1}
Precision = \frac{tp}{tp+fp} 
\end{equation}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.45\linewidth}
\centering
\begin{equation}\label{eq-2}
Recall = \frac{tp}{tp+fn}
\end{equation}
\end{minipage}
\end{figure}


\begin{equation}\label{eq-3}
F1 = 2 \cdot \frac{Precision \cdot Recall}{ Precision + Recall}
\end{equation}


\subsection{Sample}
This experiment has been carried out using the next datasets:
\begin{itemize}
\item A RDF dataset of public procurement notices from 2008 to 2011 that contains $919341$ documents annotated with 
a total number of $1866367$ CPV codes ($10062$ are different) and $1438572$ NUTS codes ($1896$ are different).
\item A set of 11 real user queries and the expected set of CPV codes created by ``Euroalert.net'' employees, see Table~\ref{expected-codes} 
(queries have been ``normalized'' according to one CPV descriptor to keep privacy) .
\item The CPV dataset as Linked Data.
\end{itemize}

More specifically, Table~\ref{expected-codes} shows the description of each query where $Q_{i}$ is the identifier 
of a user query, $Q_{str}$ is the real query as a string and $\#Q^{i}_{cpv}$ is the number of expected CPV codes. Obviously, the comparison 
does not just take into account the cardinality of the output set but the CPV code.

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.3}
\begin{center}
\begin{tabular}[c]{|l|p{8.5cm}|p{4cm}|} 
\hline
  \multirow{2}{*}\textbf{$Q_{i}$} &  \textbf{User query-$Q_{str}$} &  \textbf{Number of expected CPV codes-$\#Q^{i}_{cpv}$} \\\hline
  $Q_1$ & ``Comprehensive overview over all environmental technologies renewable energy products'' & $463$ \\ \hline
  $Q_2$ & ``Tendering of public works: housing, hospitals, roads, housing developments, station drinking water treatment, reforestation'' & $35$ \\ \hline
  $Q_3$ & ``Prefabricated buildings'' & $7$ \\ \hline
  $Q_4$ & ``Games for children (parks swings, slides, land of play equipment in the public sphere'' & $26$ \\ \hline
  $Q_5$ & ``Vital signs monitor'' &  $277$\\ \hline
  $Q_6$ & ``Museum and exhibition and product launch services'' & $1$ \\ \hline
  $Q_7$ & ``Voltmeters, instruments measuring electrical quantities, Ammeters, Instruments for checking physical characteristics, hygrometers, thermometers, measuring equipment and control, leak detector, Analyzers, 
  Cable Splicing insulated cable joints kits, screwdrivers, hand tools , screwdriver'' & $117$ \\ \hline
  $Q_8$ & ``Conservation Maintenance of pavements for roads, airfields, bridges, tunnels'' & $13$ \\ \hline
  $Q_9$ & ``Wood poles, Wooden sleepers , Lattice towers'' & $10$ \\ \hline
  $Q_{10}$ & ``Architectural, construction, engineering and inspection services'' &  $173$\\ \hline
  $Q_{11}$ & ``Medical practice and related services'' &  $13$\\ \hline
 \end{tabular}
  \caption{User queries and number of expected CPV codes.}\label{expected-codes}  
    \end{center}
\end{table}


\subsection{Results and Discussion}
According to the results in Table~\ref{table:queries-ir-results}, the method that better matches the behavior 
of an expert user is $M^1$ with an average precision of $0,28$ and recall of $0,26$. This implies that a method based 
on natural language processing techniques is the most appropriate to translate user queries into CPV codes, or, at least 
is the method that better matches the translation made by business users. On the other hand, although the method $M^3$ 
with an average precision of $0,23$ and recall of $0,23$ obtains the second position it should be able to get a better 
performance exploiting semantic relationships in the CPV (maybe a training process is required to adjust the Spreading Activation algorithm). Likely, 
the type of translation that the expert user does is more close to a direct language translation than a real thinking about the 
relationships in the taxonomy. Finally, the exploitation of the historical statistics using Apache Mahout algorithms, $M^{4}$, 
(after different iterations and tests we have chosen the best configuration based on a collaborative filtering algorithm) does not 
seem to reflect the expert user behavior. Although search and recommendation should not be compared it is uncommon than a dataset containing the use CPV codes in $919341$ public procurement notices could not improve the traditional syntactic 
search. Nevertheless, there is an open issue that lies in the number of true negative codes that in a second step should 
be validated by experts, in this situation we strongly believe semantic-based methods could improve their results with regards to 
$M^1$ . 

\begin{table}[!htb]
\renewcommand{\arraystretch}{1.3}
\begin{center}
\scriptsize
\begin{tabular}{|c||c|c|c||c|c|c||c|c|c||c|c|c|}
\hline
 \textbf{$M^i$}&\multicolumn{3}{|c||}{$M^{1}$} & \multicolumn{3}{|c||}{$M^{2}$}& \multicolumn{3}{|c||}{$M^{3}$} & \multicolumn{3}{|c|}{$M^{4}$} \\ \hline
\textbf{$Q_i$}/Metric	  &\textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1} & \textbf{P} & \textbf{R} & \textbf{F1}  \\ \hline \hline
$Q_1$  	  &$0,15$ & $0,08$ & $0,10$ &		$0,15$ & $0,15$ & $0,15$ &	$0,12$ & $0,06$ & $0,08$ &	$0,06$ & $0,06$ & $0,06$ \\ \hline
$Q_2$  	  &$0,09$ & $0,09$ & $0,09$ & 		$0,06$ & $0,06$ & $0,06$ & 	$0,03$ & $0,03$ & $0,03$ & 	$0,03$ & $0,03$ & $0,03$ \\ \hline
$Q_3$  	  &$0,14$ & $0,14$ & $0,14$ & 		$0,14$ & $0,14$ & $0,14$ & 	$0,14$ & $0,14$ & $0,14$ & 	$0$ & $0$ & $0$ \\ \hline
$Q_4$  	  &$0,19$ & $0,19$ & $0,19$ &		$0$ 	& $0$ & $0$ & 		$0,12$ & $0,12$ & $0,12$ & 	$0$ & $0$ & $0$ \\ \hline
$Q_5$  	  &$0,12$ & $0,01$ & $0,02$ & 		$0,01$ & $0,01$ & $0,01$ & 	$0,08$ & $0,01$ & $0,02$ & 	$0,03$ & $0,03$ & $0,03$ \\ \hline
$Q_6$  	  &$1,00$ & $1,00$ & $1,00$ & 		$0$ & $0$ & $0$ & 		$1,00$ & $1,00$ & $1,00$ & 	$0,10$ & $0,67$ & $0,17$ \\ \hline
$Q_7$  	  &$0,20$ & $0,20$ & $0,20$ & 		$0,09$ & $0,09$ & $0,09$ & 	$0,15$ & $0,16$ & $0,15$ & 	$0,03$ & $0,03$ & $0,03$ \\ \hline
$Q_8$  	  &$0,08$ & $0,08$ & $0,08$ & 		$0,08$ & $0,08$ & $0,08$ & 	$0,08$ & $0,08$ & $0,08$ & 	$0$ & $0$ & $0$ \\ \hline
$Q_9$  	  &$0,50$ & $0,50$ & $0,50$ & 		$0$ & $0$ & $0$ & 		$0,30$ & $0,38$ & $0,34$ & 	$0$ & $0$ & $0$ \\ \hline
$Q_{10}$  &$0,39$ & $0,39$ & $0,39$ & 		$0,42$ & $0,42$ & $0,42$ & 	$0,34$ & $0,35$ & $0,34$ & 	$0,16$ & $0,16$ & $0,16$ \\ \hline
$Q_{11}$  &$0,23$ & $0,23$ & $0,23$ & 		$0,23$ & $0,23$ & $0,23$ & 	$0,15$ & $0,17$ & $0,16$ & 	$0$ & $0$ & $0$ \\ \hline
\multicolumn{13}{|c|}{\textbf{Average of quantitative measures}} \\ \hline
\textbf{Total}  &$0,28$ & $0,26$ & $0,27$ & 	$0,11$ & $0,11$ & $0,11$ &  	$0,23$ & $0,23$ & $0,224$ &  	$0,03$ & $0,03$ & $0,044$ \\ \hline
\hline
 \end{tabular}
\caption{Quantitative measures (P-precision and R-recall) of methods for recommending CPV codes.}\label{table:queries-ir-results}
  \end{center}
\end{table} 

Finally, after the execution of these experiments and back to the motivating examples 
presented in the introduction section some assertions can be done:
\begin{itemize}
 \item The American SME can now use the NAICS classification to search public procurement 
 opportunities in Europe.
 
 \item The Spanish family-owned company can access to Bulgarian low-value procurement opportunities because the 
 use of the CPV (through Internet protocols) directly supports a multilingual environment and they can also obtain suggestions of CPV codes.
 
 \item The department of statistics within the WorldBank can gather and summarize different economic data due to 
 the link among PSCs. In this case the CPV can be used as \textit{lingua franca} to make data comparisons.
 
 \item The company that sells a commercial alert service or more specifically its employees can take advantage of 
 the recommending engine to support their decisions and make a better translation of customers intentions.
\end{itemize}


